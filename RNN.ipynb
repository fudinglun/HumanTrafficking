{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import pdb\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_list_of_word(words, remove_stopping_word=False):\n",
    "    \"\"\"remove punctuations\"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    result = list(map(lambda x: x.translate(translator) , words))\n",
    "    \n",
    "    \"\"\"remove stopping word\"\"\"\n",
    "    if remove_stopping_word:\n",
    "        result = [word for word in result if word not in stopwords.words('english')]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = pd.read_table(\"../glove.6B/glove.6B.100d.txt\", sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "def vec(w):\n",
    "  return words.loc[w].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61491  ,  0.92734  ,  0.55826  ,  0.0057455, -0.67172  ,\n",
       "        0.61189  ,  0.99226  ,  0.27641  , -0.64889  , -0.51675  ,\n",
       "        1.1789   , -1.1631   , -0.90994  ,  0.5714   ,  1.0018   ,\n",
       "        0.20675  ,  0.36751  ,  0.46931  ,  0.096868 ,  1.4351   ,\n",
       "        1.3924   ,  0.4589   ,  0.65491  ,  1.0463   ,  0.11249  ,\n",
       "        0.56988  ,  0.76595  ,  0.45246  ,  0.48627  , -0.74383  ,\n",
       "       -0.21478  ,  0.7041   ,  0.068082 ,  0.54945  , -0.012204 ,\n",
       "       -0.18558  ,  0.4266   ,  0.90742  , -0.62418  ,  0.56063  ,\n",
       "        0.9091   , -1.4814   ,  0.39494  , -1.2353   ,  0.39864  ,\n",
       "       -0.86375  ,  0.51337  ,  0.36805  ,  0.2084   ,  0.068722 ,\n",
       "       -0.011695 , -0.48135  , -0.61458  ,  1.2844   , -1.2055   ,\n",
       "       -1.929    , -0.48368  , -0.67811  ,  0.15408  ,  0.15402  ,\n",
       "       -1.4051   , -1.5294   , -1.2464   , -0.38637  ,  0.89358  ,\n",
       "        0.71173  , -1.0529   ,  0.64586  , -0.16673  ,  0.53946  ,\n",
       "       -1.1164   ,  0.19146  ,  0.55717  ,  0.031212 ,  0.76968  ,\n",
       "       -0.59599  ,  0.05137  , -0.61187  , -0.56898  , -0.34163  ,\n",
       "       -0.1408   ,  0.045282 , -0.71647  , -0.29842  ,  0.16358  ,\n",
       "        0.30357  , -0.14735  ,  0.052451 , -0.15184  ,  0.83193  ,\n",
       "       -1.1335   ,  0.61988  , -0.14507  ,  0.51219  , -1.2197   ,\n",
       "       -0.39897  , -0.38261  , -0.092153 , -0.079833 , -1.2843   ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_single_sentence_embedding(sent):\n",
    "    result = []\n",
    "    for item in sent:\n",
    "        try:\n",
    "            result.append(np.array(vec(item)))\n",
    "        except:\n",
    "            result.append(np.array(vec(\",\")))\n",
    "            continue\n",
    "    return np.array(result)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_embedding(sent_list):\n",
    "    max_len = max(list(map(len, sent_list)))\n",
    "    result = []\n",
    "    for sent in sent_list:\n",
    "        result.append(get_single_sentence_embedding(sent + [\".\"]*(max_len - len(sent))))\n",
    "    return np.array(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dimension, hidden_dimension, batch_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.input_dim = input_dimension\n",
    "        self.hidden_dim = hidden_dimension\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dimension, hidden_dimension, bidirectional=False)\n",
    "        self.fc = nn.Linear(hidden_dimension, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, hidden, c):\n",
    "        x = x.transpose(0, 1)\n",
    "        len_seq = len(x)\n",
    "        outputs, last = self.lstm(x, (hidden, c))\n",
    "        output = self.fc(last[0])\n",
    "        output = self.sigmoid(output)\n",
    "        return output.squeeze()\n",
    "           \n",
    "    def init_hidden(self):\n",
    "        h0 = Variable(torch.randn(1, self.batch_size, self.hidden_dim))\n",
    "        c0 = Variable(torch.randn(1, self.batch_size, self.hidden_dim))\n",
    "        return h0, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../all_ter_data_dropna.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_list = list(df.loc[df['ht'] == 1.0][])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_list = list(df.loc[df['ht'] == 0.0]['Unnamed: 0'])[:16082]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_list = one_list + zero_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Loss: 0.6953133344650269\n",
      "Epoch: 0, Step: 200, Loss: 0.6957678198814392\n",
      "Epoch: 0, Step: 400, Loss: 0.6927761435508728\n",
      "Epoch: 0, Step: 600, Loss: 0.6943928003311157\n",
      "Epoch: 1, Step: 0, Loss: 0.6944343447685242\n",
      "Epoch: 1, Step: 200, Loss: 0.6959816217422485\n",
      "Epoch: 1, Step: 400, Loss: 0.6927227973937988\n",
      "Epoch: 1, Step: 600, Loss: 0.6943374872207642\n",
      "Epoch: 2, Step: 0, Loss: 0.6945720911026001\n",
      "Epoch: 2, Step: 200, Loss: 0.6959515810012817\n",
      "Epoch: 2, Step: 400, Loss: 0.6927058696746826\n",
      "Epoch: 2, Step: 600, Loss: 0.694332480430603\n",
      "Epoch: 3, Step: 0, Loss: 0.6946743726730347\n",
      "Epoch: 3, Step: 200, Loss: 0.6959359049797058\n",
      "Epoch: 3, Step: 400, Loss: 0.6926993131637573\n",
      "Epoch: 3, Step: 600, Loss: 0.6943338513374329\n",
      "Epoch: 4, Step: 0, Loss: 0.6947702169418335\n",
      "Epoch: 4, Step: 200, Loss: 0.695929229259491\n",
      "Epoch: 4, Step: 400, Loss: 0.6926904320716858\n",
      "Epoch: 4, Step: 600, Loss: 0.6943276524543762\n",
      "Epoch: 5, Step: 0, Loss: 0.6948450803756714\n",
      "Epoch: 5, Step: 200, Loss: 0.6959184408187866\n",
      "Epoch: 5, Step: 400, Loss: 0.6926883459091187\n",
      "Epoch: 5, Step: 600, Loss: 0.6943240761756897\n",
      "Epoch: 6, Step: 0, Loss: 0.6949423551559448\n",
      "Epoch: 6, Step: 200, Loss: 0.6959152221679688\n",
      "Epoch: 6, Step: 400, Loss: 0.6926747560501099\n",
      "Epoch: 6, Step: 600, Loss: 0.694320559501648\n",
      "Epoch: 7, Step: 0, Loss: 0.6950118541717529\n",
      "Epoch: 7, Step: 200, Loss: 0.6959191560745239\n",
      "Epoch: 7, Step: 400, Loss: 0.6926608085632324\n",
      "Epoch: 7, Step: 600, Loss: 0.6943180561065674\n",
      "Epoch: 8, Step: 0, Loss: 0.6950811743736267\n",
      "Epoch: 8, Step: 200, Loss: 0.6959181427955627\n",
      "Epoch: 8, Step: 400, Loss: 0.6926413178443909\n",
      "Epoch: 8, Step: 600, Loss: 0.6943117380142212\n",
      "Epoch: 9, Step: 0, Loss: 0.6951558589935303\n",
      "Epoch: 9, Step: 200, Loss: 0.6959251165390015\n",
      "Epoch: 9, Step: 400, Loss: 0.69261634349823\n",
      "Epoch: 9, Step: 600, Loss: 0.6943081021308899\n",
      "Epoch: 10, Step: 0, Loss: 0.6952236890792847\n",
      "Epoch: 10, Step: 200, Loss: 0.6959314346313477\n",
      "Epoch: 10, Step: 400, Loss: 0.6925874948501587\n",
      "Epoch: 10, Step: 600, Loss: 0.6943008899688721\n",
      "Epoch: 11, Step: 0, Loss: 0.6952990889549255\n",
      "Epoch: 11, Step: 200, Loss: 0.6959376335144043\n",
      "Epoch: 11, Step: 400, Loss: 0.6925480961799622\n",
      "Epoch: 11, Step: 600, Loss: 0.694294810295105\n",
      "Epoch: 12, Step: 0, Loss: 0.6953713297843933\n",
      "Epoch: 12, Step: 200, Loss: 0.695950448513031\n",
      "Epoch: 12, Step: 400, Loss: 0.6925065517425537\n",
      "Epoch: 12, Step: 600, Loss: 0.694280743598938\n",
      "Epoch: 13, Step: 0, Loss: 0.695442795753479\n",
      "Epoch: 13, Step: 200, Loss: 0.695968508720398\n",
      "Epoch: 13, Step: 400, Loss: 0.6924532055854797\n",
      "Epoch: 13, Step: 600, Loss: 0.6942703723907471\n",
      "Epoch: 14, Step: 0, Loss: 0.6955201029777527\n",
      "Epoch: 14, Step: 200, Loss: 0.6959893703460693\n",
      "Epoch: 14, Step: 400, Loss: 0.6923824548721313\n",
      "Epoch: 14, Step: 600, Loss: 0.694256603717804\n",
      "Epoch: 15, Step: 0, Loss: 0.6956039071083069\n",
      "Epoch: 15, Step: 200, Loss: 0.6960150003433228\n",
      "Epoch: 15, Step: 400, Loss: 0.6923015117645264\n",
      "Epoch: 15, Step: 600, Loss: 0.6942407488822937\n",
      "Epoch: 16, Step: 0, Loss: 0.6956984996795654\n",
      "Epoch: 16, Step: 200, Loss: 0.6960476636886597\n",
      "Epoch: 16, Step: 400, Loss: 0.6922065019607544\n",
      "Epoch: 16, Step: 600, Loss: 0.694219172000885\n",
      "Epoch: 17, Step: 0, Loss: 0.6957941055297852\n",
      "Epoch: 17, Step: 200, Loss: 0.6960840821266174\n",
      "Epoch: 17, Step: 400, Loss: 0.6920918822288513\n",
      "Epoch: 17, Step: 600, Loss: 0.6942049860954285\n",
      "Epoch: 18, Step: 0, Loss: 0.6958949565887451\n",
      "Epoch: 18, Step: 200, Loss: 0.6961256861686707\n",
      "Epoch: 18, Step: 400, Loss: 0.6919689774513245\n",
      "Epoch: 18, Step: 600, Loss: 0.6941791772842407\n",
      "Epoch: 19, Step: 0, Loss: 0.695999026298523\n",
      "Epoch: 19, Step: 200, Loss: 0.6961637735366821\n",
      "Epoch: 19, Step: 400, Loss: 0.6918386220932007\n",
      "Epoch: 19, Step: 600, Loss: 0.694151759147644\n",
      "Epoch: 20, Step: 0, Loss: 0.6961076855659485\n",
      "Epoch: 20, Step: 200, Loss: 0.6962135434150696\n",
      "Epoch: 20, Step: 400, Loss: 0.6916958093643188\n",
      "Epoch: 20, Step: 600, Loss: 0.6941300630569458\n",
      "Epoch: 21, Step: 0, Loss: 0.6962058544158936\n",
      "Epoch: 21, Step: 200, Loss: 0.6962616443634033\n",
      "Epoch: 21, Step: 400, Loss: 0.691564679145813\n",
      "Epoch: 21, Step: 600, Loss: 0.6941088438034058\n",
      "Epoch: 22, Step: 0, Loss: 0.6963066458702087\n",
      "Epoch: 22, Step: 200, Loss: 0.6962980031967163\n",
      "Epoch: 22, Step: 400, Loss: 0.6914272904396057\n",
      "Epoch: 22, Step: 600, Loss: 0.6940890550613403\n",
      "Epoch: 23, Step: 0, Loss: 0.6963914632797241\n",
      "Epoch: 23, Step: 200, Loss: 0.6963417530059814\n",
      "Epoch: 23, Step: 400, Loss: 0.6913079619407654\n",
      "Epoch: 23, Step: 600, Loss: 0.6940699815750122\n",
      "Epoch: 24, Step: 0, Loss: 0.6964713931083679\n",
      "Epoch: 24, Step: 200, Loss: 0.6963775157928467\n",
      "Epoch: 24, Step: 400, Loss: 0.6912044286727905\n",
      "Epoch: 24, Step: 600, Loss: 0.6940540075302124\n",
      "Epoch: 25, Step: 0, Loss: 0.6965418457984924\n",
      "Epoch: 25, Step: 200, Loss: 0.6964126825332642\n",
      "Epoch: 25, Step: 400, Loss: 0.6911038756370544\n",
      "Epoch: 25, Step: 600, Loss: 0.6940436363220215\n",
      "Epoch: 26, Step: 0, Loss: 0.6966007947921753\n",
      "Epoch: 26, Step: 200, Loss: 0.6964342594146729\n",
      "Epoch: 26, Step: 400, Loss: 0.6910296678543091\n",
      "Epoch: 26, Step: 600, Loss: 0.6940256953239441\n",
      "Epoch: 27, Step: 0, Loss: 0.6966451406478882\n",
      "Epoch: 27, Step: 200, Loss: 0.6964577436447144\n",
      "Epoch: 27, Step: 400, Loss: 0.6909526586532593\n",
      "Epoch: 27, Step: 600, Loss: 0.6940199136734009\n",
      "Epoch: 28, Step: 0, Loss: 0.6966801881790161\n",
      "Epoch: 28, Step: 200, Loss: 0.6964796781539917\n",
      "Epoch: 28, Step: 400, Loss: 0.6908999681472778\n",
      "Epoch: 28, Step: 600, Loss: 0.694015383720398\n",
      "Epoch: 29, Step: 0, Loss: 0.6967180371284485\n",
      "Epoch: 29, Step: 200, Loss: 0.6964948773384094\n",
      "Epoch: 29, Step: 400, Loss: 0.6908581852912903\n",
      "Epoch: 29, Step: 600, Loss: 0.6940060257911682\n",
      "Epoch: 30, Step: 0, Loss: 0.696734607219696\n",
      "Epoch: 30, Step: 200, Loss: 0.6965059638023376\n",
      "Epoch: 30, Step: 400, Loss: 0.6908189058303833\n",
      "Epoch: 30, Step: 600, Loss: 0.6940040588378906\n",
      "Epoch: 31, Step: 0, Loss: 0.6967613697052002\n",
      "Epoch: 31, Step: 200, Loss: 0.6965155005455017\n",
      "Epoch: 31, Step: 400, Loss: 0.6907898187637329\n",
      "Epoch: 31, Step: 600, Loss: 0.6940015554428101\n",
      "Epoch: 32, Step: 0, Loss: 0.6967757940292358\n",
      "Epoch: 32, Step: 200, Loss: 0.6965259313583374\n",
      "Epoch: 32, Step: 400, Loss: 0.6907600164413452\n",
      "Epoch: 32, Step: 600, Loss: 0.6939973831176758\n",
      "Epoch: 33, Step: 0, Loss: 0.6967989802360535\n",
      "Epoch: 33, Step: 200, Loss: 0.696534276008606\n",
      "Epoch: 33, Step: 400, Loss: 0.6907413601875305\n",
      "Epoch: 33, Step: 600, Loss: 0.6939972639083862\n",
      "Epoch: 34, Step: 0, Loss: 0.6968063712120056\n",
      "Epoch: 34, Step: 200, Loss: 0.6965381503105164\n",
      "Epoch: 34, Step: 400, Loss: 0.6907211542129517\n",
      "Epoch: 34, Step: 600, Loss: 0.6939971446990967\n",
      "Epoch: 35, Step: 0, Loss: 0.6968083381652832\n",
      "Epoch: 35, Step: 200, Loss: 0.6965389847755432\n",
      "Epoch: 35, Step: 400, Loss: 0.6907017827033997\n",
      "Epoch: 35, Step: 600, Loss: 0.6939952373504639\n",
      "Epoch: 36, Step: 0, Loss: 0.6968145966529846\n",
      "Epoch: 36, Step: 200, Loss: 0.6965516805648804\n",
      "Epoch: 36, Step: 400, Loss: 0.6906918287277222\n",
      "Epoch: 36, Step: 600, Loss: 0.6939959526062012\n",
      "Epoch: 37, Step: 0, Loss: 0.6968063116073608\n",
      "Epoch: 37, Step: 200, Loss: 0.6965484619140625\n",
      "Epoch: 37, Step: 400, Loss: 0.6906744837760925\n",
      "Epoch: 37, Step: 600, Loss: 0.6939958930015564\n",
      "Epoch: 38, Step: 0, Loss: 0.6968055367469788\n",
      "Epoch: 38, Step: 200, Loss: 0.696557879447937\n",
      "Epoch: 38, Step: 400, Loss: 0.6906687021255493\n",
      "Epoch: 38, Step: 600, Loss: 0.6939937472343445\n",
      "Epoch: 39, Step: 0, Loss: 0.696808934211731\n",
      "Epoch: 39, Step: 200, Loss: 0.696557879447937\n",
      "Epoch: 39, Step: 400, Loss: 0.6906567811965942\n",
      "Epoch: 39, Step: 600, Loss: 0.6939936876296997\n",
      "Epoch: 40, Step: 0, Loss: 0.6967933773994446\n",
      "Epoch: 40, Step: 200, Loss: 0.6965535879135132\n",
      "Epoch: 40, Step: 400, Loss: 0.6906510591506958\n",
      "Epoch: 40, Step: 600, Loss: 0.6939915418624878\n",
      "Epoch: 41, Step: 0, Loss: 0.6967984437942505\n",
      "Epoch: 41, Step: 200, Loss: 0.6965638399124146\n",
      "Epoch: 41, Step: 400, Loss: 0.6906400918960571\n",
      "Epoch: 41, Step: 600, Loss: 0.6939903497695923\n",
      "Epoch: 42, Step: 0, Loss: 0.6967899799346924\n",
      "Epoch: 42, Step: 200, Loss: 0.6965574026107788\n",
      "Epoch: 42, Step: 400, Loss: 0.6906309127807617\n",
      "Epoch: 42, Step: 600, Loss: 0.6939839124679565\n",
      "Epoch: 43, Step: 0, Loss: 0.6967787742614746\n",
      "Epoch: 43, Step: 200, Loss: 0.6965628266334534\n",
      "Epoch: 43, Step: 400, Loss: 0.6906205415725708\n",
      "Epoch: 43, Step: 600, Loss: 0.6939971446990967\n",
      "Epoch: 44, Step: 0, Loss: 0.6967836618423462\n",
      "Epoch: 44, Step: 200, Loss: 0.6965696811676025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Step: 400, Loss: 0.6906159520149231\n",
      "Epoch: 44, Step: 600, Loss: 0.6939963102340698\n",
      "Epoch: 45, Step: 0, Loss: 0.6967888474464417\n",
      "Epoch: 45, Step: 200, Loss: 0.6965638399124146\n",
      "Epoch: 45, Step: 400, Loss: 0.6905968189239502\n",
      "Epoch: 45, Step: 600, Loss: 0.6940005421638489\n",
      "Epoch: 46, Step: 0, Loss: 0.6967501640319824\n",
      "Epoch: 46, Step: 200, Loss: 0.696571946144104\n",
      "Epoch: 46, Step: 400, Loss: 0.6905994415283203\n",
      "Epoch: 46, Step: 600, Loss: 0.6939903497695923\n",
      "Epoch: 47, Step: 0, Loss: 0.6967341303825378\n",
      "Epoch: 47, Step: 200, Loss: 0.6965646743774414\n",
      "Epoch: 47, Step: 400, Loss: 0.6906052827835083\n",
      "Epoch: 47, Step: 600, Loss: 0.694008469581604\n",
      "Epoch: 48, Step: 0, Loss: 0.6967126131057739\n",
      "Epoch: 48, Step: 200, Loss: 0.6965678930282593\n",
      "Epoch: 48, Step: 400, Loss: 0.6905998587608337\n",
      "Epoch: 48, Step: 600, Loss: 0.6940034031867981\n",
      "Epoch: 49, Step: 0, Loss: 0.6967161893844604\n",
      "Epoch: 49, Step: 200, Loss: 0.6965616941452026\n",
      "Epoch: 49, Step: 400, Loss: 0.6905855536460876\n",
      "Epoch: 49, Step: 600, Loss: 0.6939960718154907\n",
      "Epoch: 50, Step: 0, Loss: 0.6966861486434937\n",
      "Epoch: 50, Step: 200, Loss: 0.6965781450271606\n",
      "Epoch: 50, Step: 400, Loss: 0.6905977725982666\n",
      "Epoch: 50, Step: 600, Loss: 0.6939945816993713\n",
      "Epoch: 51, Step: 0, Loss: 0.6967055201530457\n",
      "Epoch: 51, Step: 200, Loss: 0.6965607404708862\n",
      "Epoch: 51, Step: 400, Loss: 0.6905902624130249\n",
      "Epoch: 51, Step: 600, Loss: 0.6939891576766968\n",
      "Epoch: 52, Step: 0, Loss: 0.6966720819473267\n",
      "Epoch: 52, Step: 200, Loss: 0.6965776085853577\n",
      "Epoch: 52, Step: 400, Loss: 0.6905980110168457\n",
      "Epoch: 52, Step: 600, Loss: 0.6939905881881714\n",
      "Epoch: 53, Step: 0, Loss: 0.6966476440429688\n",
      "Epoch: 53, Step: 200, Loss: 0.6965650320053101\n",
      "Epoch: 53, Step: 400, Loss: 0.6905699372291565\n",
      "Epoch: 53, Step: 600, Loss: 0.6940038204193115\n",
      "Epoch: 54, Step: 0, Loss: 0.6966268420219421\n",
      "Epoch: 54, Step: 200, Loss: 0.6965574622154236\n",
      "Epoch: 54, Step: 400, Loss: 0.6905649304389954\n",
      "Epoch: 54, Step: 600, Loss: 0.6939926743507385\n",
      "Epoch: 55, Step: 0, Loss: 0.6966007947921753\n",
      "Epoch: 55, Step: 200, Loss: 0.6965731382369995\n",
      "Epoch: 55, Step: 400, Loss: 0.6905757188796997\n",
      "Epoch: 55, Step: 600, Loss: 0.694017231464386\n",
      "Epoch: 56, Step: 0, Loss: 0.6965686678886414\n",
      "Epoch: 56, Step: 200, Loss: 0.6965758204460144\n",
      "Epoch: 56, Step: 400, Loss: 0.6905704736709595\n",
      "Epoch: 56, Step: 600, Loss: 0.6940130591392517\n",
      "Epoch: 57, Step: 0, Loss: 0.6965126991271973\n",
      "Epoch: 57, Step: 200, Loss: 0.6965815424919128\n",
      "Epoch: 57, Step: 400, Loss: 0.6905902028083801\n",
      "Epoch: 57, Step: 600, Loss: 0.6939976811408997\n",
      "Epoch: 58, Step: 0, Loss: 0.69650799036026\n",
      "Epoch: 58, Step: 200, Loss: 0.6965534090995789\n",
      "Epoch: 58, Step: 400, Loss: 0.6906226277351379\n",
      "Epoch: 58, Step: 600, Loss: 0.6939970254898071\n",
      "Epoch: 59, Step: 0, Loss: 0.6964406371116638\n",
      "Epoch: 59, Step: 200, Loss: 0.6966218948364258\n",
      "Epoch: 59, Step: 400, Loss: 0.6905590295791626\n",
      "Epoch: 59, Step: 600, Loss: 0.6939894556999207\n",
      "Epoch: 60, Step: 0, Loss: 0.6963531374931335\n",
      "Epoch: 60, Step: 200, Loss: 0.6965851783752441\n",
      "Epoch: 60, Step: 400, Loss: 0.6906269788742065\n",
      "Epoch: 60, Step: 600, Loss: 0.6940658092498779\n",
      "Epoch: 61, Step: 0, Loss: 0.6964063048362732\n",
      "Epoch: 61, Step: 200, Loss: 0.6965272426605225\n",
      "Epoch: 61, Step: 400, Loss: 0.6908310651779175\n",
      "Epoch: 61, Step: 600, Loss: 0.6940044164657593\n",
      "Epoch: 62, Step: 0, Loss: 0.6957660913467407\n",
      "Epoch: 62, Step: 200, Loss: 0.6968632936477661\n",
      "Epoch: 62, Step: 400, Loss: 0.6914917230606079\n",
      "Epoch: 62, Step: 600, Loss: 0.6933468580245972\n",
      "Epoch: 63, Step: 0, Loss: 0.6961092352867126\n",
      "Epoch: 63, Step: 200, Loss: 0.696825385093689\n",
      "Epoch: 63, Step: 400, Loss: 0.694552481174469\n",
      "Epoch: 63, Step: 600, Loss: 0.6937218904495239\n",
      "Epoch: 64, Step: 0, Loss: 0.6960257887840271\n",
      "Epoch: 64, Step: 200, Loss: 0.6746343970298767\n",
      "Epoch: 64, Step: 400, Loss: 0.6974840760231018\n",
      "Epoch: 64, Step: 600, Loss: 0.6944407224655151\n",
      "Epoch: 65, Step: 0, Loss: 0.6831257343292236\n",
      "Epoch: 65, Step: 200, Loss: 0.6750441789627075\n",
      "Epoch: 65, Step: 400, Loss: 0.6785592436790466\n",
      "Epoch: 65, Step: 600, Loss: 0.6831473112106323\n",
      "Epoch: 66, Step: 0, Loss: 0.675404965877533\n",
      "Epoch: 66, Step: 200, Loss: 0.6858848333358765\n",
      "Epoch: 66, Step: 400, Loss: 0.699952244758606\n",
      "Epoch: 66, Step: 600, Loss: 0.7208316326141357\n",
      "Epoch: 67, Step: 0, Loss: 0.6688428521156311\n",
      "Epoch: 67, Step: 200, Loss: 0.6643242239952087\n",
      "Epoch: 67, Step: 400, Loss: 0.7117391228675842\n",
      "Epoch: 67, Step: 600, Loss: 0.6998980045318604\n",
      "Epoch: 68, Step: 0, Loss: 0.680345892906189\n",
      "Epoch: 68, Step: 200, Loss: 0.6494579315185547\n",
      "Epoch: 68, Step: 400, Loss: 0.6737675666809082\n",
      "Epoch: 68, Step: 600, Loss: 0.6966170072555542\n",
      "Epoch: 69, Step: 0, Loss: 0.6566994190216064\n",
      "Epoch: 69, Step: 200, Loss: 0.6019267439842224\n",
      "Epoch: 69, Step: 400, Loss: 0.6514895558357239\n",
      "Epoch: 69, Step: 600, Loss: 0.6981273293495178\n",
      "Epoch: 70, Step: 0, Loss: 0.6524513363838196\n",
      "Epoch: 70, Step: 200, Loss: 0.5966118574142456\n",
      "Epoch: 70, Step: 400, Loss: 0.6607586145401001\n",
      "Epoch: 70, Step: 600, Loss: 0.6986089944839478\n",
      "Epoch: 71, Step: 0, Loss: 0.6492213010787964\n",
      "Epoch: 71, Step: 200, Loss: 0.5936213135719299\n",
      "Epoch: 71, Step: 400, Loss: 0.6548508405685425\n",
      "Epoch: 71, Step: 600, Loss: 0.7108416557312012\n",
      "Epoch: 72, Step: 0, Loss: 0.6458607912063599\n",
      "Epoch: 72, Step: 200, Loss: 0.5742107033729553\n",
      "Epoch: 72, Step: 400, Loss: 0.6520346403121948\n",
      "Epoch: 72, Step: 600, Loss: 0.6820654273033142\n",
      "Epoch: 73, Step: 0, Loss: 0.6489485502243042\n",
      "Epoch: 73, Step: 200, Loss: 0.570231020450592\n",
      "Epoch: 73, Step: 400, Loss: 0.6516212224960327\n",
      "Epoch: 73, Step: 600, Loss: 0.6955873370170593\n",
      "Epoch: 74, Step: 0, Loss: 0.6465521454811096\n",
      "Epoch: 74, Step: 200, Loss: 0.5640290975570679\n",
      "Epoch: 74, Step: 400, Loss: 0.6477681398391724\n",
      "Epoch: 74, Step: 600, Loss: 0.6857739090919495\n",
      "Epoch: 75, Step: 0, Loss: 0.6481887102127075\n",
      "Epoch: 75, Step: 200, Loss: 0.5731247067451477\n",
      "Epoch: 75, Step: 400, Loss: 0.6442523002624512\n",
      "Epoch: 75, Step: 600, Loss: 0.6826300621032715\n",
      "Epoch: 76, Step: 0, Loss: 0.6484121084213257\n",
      "Epoch: 76, Step: 200, Loss: 0.577175498008728\n",
      "Epoch: 76, Step: 400, Loss: 0.6398172974586487\n",
      "Epoch: 76, Step: 600, Loss: 0.6904335618019104\n",
      "Epoch: 77, Step: 0, Loss: 0.6589266657829285\n",
      "Epoch: 77, Step: 200, Loss: 0.5646941065788269\n",
      "Epoch: 77, Step: 400, Loss: 0.6340410113334656\n",
      "Epoch: 77, Step: 600, Loss: 0.7012045383453369\n",
      "Epoch: 78, Step: 0, Loss: 0.6398443579673767\n",
      "Epoch: 78, Step: 200, Loss: 0.5695744752883911\n",
      "Epoch: 78, Step: 400, Loss: 0.6284134984016418\n",
      "Epoch: 78, Step: 600, Loss: 0.7114867568016052\n",
      "Epoch: 79, Step: 0, Loss: 0.6382921934127808\n",
      "Epoch: 79, Step: 200, Loss: 0.5646511316299438\n",
      "Epoch: 79, Step: 400, Loss: 0.6171030402183533\n",
      "Epoch: 79, Step: 600, Loss: 0.7206241488456726\n",
      "Epoch: 80, Step: 0, Loss: 0.6342933773994446\n",
      "Epoch: 80, Step: 200, Loss: 0.5669416189193726\n",
      "Epoch: 80, Step: 400, Loss: 0.6143921613693237\n",
      "Epoch: 80, Step: 600, Loss: 0.7066764235496521\n",
      "Epoch: 81, Step: 0, Loss: 0.631794810295105\n",
      "Epoch: 81, Step: 200, Loss: 0.5780611038208008\n",
      "Epoch: 81, Step: 400, Loss: 0.6099108457565308\n",
      "Epoch: 81, Step: 600, Loss: 0.7018040418624878\n",
      "Epoch: 82, Step: 0, Loss: 0.631644606590271\n",
      "Epoch: 82, Step: 200, Loss: 0.5688489675521851\n",
      "Epoch: 82, Step: 400, Loss: 0.5935577154159546\n",
      "Epoch: 82, Step: 600, Loss: 0.7012362480163574\n",
      "Epoch: 83, Step: 0, Loss: 0.6238263845443726\n",
      "Epoch: 83, Step: 200, Loss: 0.5700190663337708\n",
      "Epoch: 83, Step: 400, Loss: 0.5912964940071106\n",
      "Epoch: 83, Step: 600, Loss: 0.700710654258728\n",
      "Epoch: 84, Step: 0, Loss: 0.625745952129364\n",
      "Epoch: 84, Step: 200, Loss: 0.5624509453773499\n",
      "Epoch: 84, Step: 400, Loss: 0.5858496427536011\n",
      "Epoch: 84, Step: 600, Loss: 0.6985312104225159\n",
      "Epoch: 85, Step: 0, Loss: 0.6190821528434753\n",
      "Epoch: 85, Step: 200, Loss: 0.5631202459335327\n",
      "Epoch: 85, Step: 400, Loss: 0.5860794186592102\n",
      "Epoch: 85, Step: 600, Loss: 0.6883872747421265\n",
      "Epoch: 86, Step: 0, Loss: 0.6217032670974731\n",
      "Epoch: 86, Step: 200, Loss: 0.5603469610214233\n",
      "Epoch: 86, Step: 400, Loss: 0.5810830593109131\n",
      "Epoch: 86, Step: 600, Loss: 0.7018061876296997\n",
      "Epoch: 87, Step: 0, Loss: 0.6194093823432922\n",
      "Epoch: 87, Step: 200, Loss: 0.5585811138153076\n",
      "Epoch: 87, Step: 400, Loss: 0.5755196809768677\n",
      "Epoch: 87, Step: 600, Loss: 0.7042912244796753\n",
      "Epoch: 88, Step: 0, Loss: 0.6171371936798096\n",
      "Epoch: 88, Step: 200, Loss: 0.5638912916183472\n",
      "Epoch: 88, Step: 400, Loss: 0.5729701519012451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88, Step: 600, Loss: 0.6961992979049683\n",
      "Epoch: 89, Step: 0, Loss: 0.6037851572036743\n",
      "Epoch: 89, Step: 200, Loss: 0.5572724342346191\n",
      "Epoch: 89, Step: 400, Loss: 0.572045087814331\n",
      "Epoch: 89, Step: 600, Loss: 0.6999374628067017\n",
      "Epoch: 90, Step: 0, Loss: 0.6211358904838562\n",
      "Epoch: 90, Step: 200, Loss: 0.5547441244125366\n",
      "Epoch: 90, Step: 400, Loss: 0.5641446113586426\n",
      "Epoch: 90, Step: 600, Loss: 0.7005079984664917\n",
      "Epoch: 91, Step: 0, Loss: 0.6142944097518921\n",
      "Epoch: 91, Step: 200, Loss: 0.5596771836280823\n",
      "Epoch: 91, Step: 400, Loss: 0.5648335814476013\n",
      "Epoch: 91, Step: 600, Loss: 0.7090256810188293\n",
      "Epoch: 92, Step: 0, Loss: 0.613610565662384\n",
      "Epoch: 92, Step: 200, Loss: 0.5522481203079224\n",
      "Epoch: 92, Step: 400, Loss: 0.5579447746276855\n",
      "Epoch: 92, Step: 600, Loss: 0.7096544504165649\n",
      "Epoch: 93, Step: 0, Loss: 0.6134659051895142\n",
      "Epoch: 93, Step: 200, Loss: 0.5331973433494568\n",
      "Epoch: 93, Step: 400, Loss: 0.5550416707992554\n",
      "Epoch: 93, Step: 600, Loss: 0.7090858221054077\n",
      "Epoch: 94, Step: 0, Loss: 0.6128572225570679\n",
      "Epoch: 94, Step: 200, Loss: 0.5452314615249634\n",
      "Epoch: 94, Step: 400, Loss: 0.5496443510055542\n",
      "Epoch: 94, Step: 600, Loss: 0.6945850253105164\n",
      "Epoch: 95, Step: 0, Loss: 0.6096184253692627\n",
      "Epoch: 95, Step: 200, Loss: 0.5218952298164368\n",
      "Epoch: 95, Step: 400, Loss: 0.5484060049057007\n",
      "Epoch: 95, Step: 600, Loss: 0.7114779353141785\n",
      "Epoch: 96, Step: 0, Loss: 0.6164426207542419\n",
      "Epoch: 96, Step: 200, Loss: 0.5285128355026245\n",
      "Epoch: 96, Step: 400, Loss: 0.5439903736114502\n",
      "Epoch: 96, Step: 600, Loss: 0.7060216665267944\n",
      "Epoch: 97, Step: 0, Loss: 0.6112755537033081\n",
      "Epoch: 97, Step: 200, Loss: 0.5225860476493835\n",
      "Epoch: 97, Step: 400, Loss: 0.5438228845596313\n",
      "Epoch: 97, Step: 600, Loss: 0.7145258784294128\n",
      "Epoch: 98, Step: 0, Loss: 0.6068852543830872\n",
      "Epoch: 98, Step: 200, Loss: 0.5248149633407593\n",
      "Epoch: 98, Step: 400, Loss: 0.540565013885498\n",
      "Epoch: 98, Step: 600, Loss: 0.7105892300605774\n",
      "Epoch: 99, Step: 0, Loss: 0.6067726016044617\n",
      "Epoch: 99, Step: 200, Loss: 0.5141387581825256\n",
      "Epoch: 99, Step: 400, Loss: 0.5433387160301208\n",
      "Epoch: 99, Step: 600, Loss: 0.7016865611076355\n",
      "Epoch: 100, Step: 0, Loss: 0.6059183478355408\n",
      "Epoch: 100, Step: 200, Loss: 0.5153836607933044\n",
      "Epoch: 100, Step: 400, Loss: 0.5394614338874817\n",
      "Epoch: 100, Step: 600, Loss: 0.7052665948867798\n",
      "Epoch: 101, Step: 0, Loss: 0.6066712141036987\n",
      "Epoch: 101, Step: 200, Loss: 0.5149056911468506\n",
      "Epoch: 101, Step: 400, Loss: 0.5446834564208984\n",
      "Epoch: 101, Step: 600, Loss: 0.7052156925201416\n",
      "Epoch: 102, Step: 0, Loss: 0.6092762351036072\n",
      "Epoch: 102, Step: 200, Loss: 0.5121140480041504\n",
      "Epoch: 102, Step: 400, Loss: 0.5331370234489441\n",
      "Epoch: 102, Step: 600, Loss: 0.7202139496803284\n",
      "Epoch: 103, Step: 0, Loss: 0.6133490204811096\n",
      "Epoch: 103, Step: 200, Loss: 0.5124549865722656\n",
      "Epoch: 103, Step: 400, Loss: 0.5435459613800049\n",
      "Epoch: 103, Step: 600, Loss: 0.7143491506576538\n",
      "Epoch: 104, Step: 0, Loss: 0.6198357939720154\n",
      "Epoch: 104, Step: 200, Loss: 0.5088459253311157\n",
      "Epoch: 104, Step: 400, Loss: 0.5454869866371155\n",
      "Epoch: 104, Step: 600, Loss: 0.7071737051010132\n",
      "Epoch: 105, Step: 0, Loss: 0.624130368232727\n",
      "Epoch: 105, Step: 200, Loss: 0.5060309171676636\n",
      "Epoch: 105, Step: 400, Loss: 0.5498298406600952\n",
      "Epoch: 105, Step: 600, Loss: 0.711530327796936\n",
      "Epoch: 106, Step: 0, Loss: 0.6274698972702026\n",
      "Epoch: 106, Step: 200, Loss: 0.5019558072090149\n",
      "Epoch: 106, Step: 400, Loss: 0.5311311483383179\n",
      "Epoch: 106, Step: 600, Loss: 0.7028507590293884\n",
      "Epoch: 107, Step: 0, Loss: 0.629540205001831\n",
      "Epoch: 107, Step: 200, Loss: 0.4975352883338928\n",
      "Epoch: 107, Step: 400, Loss: 0.543830156326294\n",
      "Epoch: 107, Step: 600, Loss: 0.705960750579834\n",
      "Epoch: 108, Step: 0, Loss: 0.6187787055969238\n",
      "Epoch: 108, Step: 200, Loss: 0.4880290627479553\n",
      "Epoch: 108, Step: 400, Loss: 0.5205003023147583\n",
      "Epoch: 108, Step: 600, Loss: 0.7173810005187988\n",
      "Epoch: 109, Step: 0, Loss: 0.6222133040428162\n",
      "Epoch: 109, Step: 200, Loss: 0.5017796754837036\n",
      "Epoch: 109, Step: 400, Loss: 0.513579785823822\n",
      "Epoch: 109, Step: 600, Loss: 0.7074617147445679\n",
      "Epoch: 110, Step: 0, Loss: 0.6107501983642578\n",
      "Epoch: 110, Step: 200, Loss: 0.47111567854881287\n",
      "Epoch: 110, Step: 400, Loss: 0.5070650577545166\n",
      "Epoch: 110, Step: 600, Loss: 0.6865026354789734\n",
      "Epoch: 111, Step: 0, Loss: 0.6178569793701172\n",
      "Epoch: 111, Step: 200, Loss: 0.46710696816444397\n",
      "Epoch: 111, Step: 400, Loss: 0.5104759335517883\n",
      "Epoch: 111, Step: 600, Loss: 0.6827113032341003\n",
      "Epoch: 112, Step: 0, Loss: 0.5960615277290344\n",
      "Epoch: 112, Step: 200, Loss: 0.4674281179904938\n",
      "Epoch: 112, Step: 400, Loss: 0.5012401938438416\n",
      "Epoch: 112, Step: 600, Loss: 0.6658562421798706\n",
      "Epoch: 113, Step: 0, Loss: 0.5759378671646118\n",
      "Epoch: 113, Step: 200, Loss: 0.4542379379272461\n",
      "Epoch: 113, Step: 400, Loss: 0.4642789363861084\n",
      "Epoch: 113, Step: 600, Loss: 0.6640039682388306\n",
      "Epoch: 114, Step: 0, Loss: 0.5834266543388367\n",
      "Epoch: 114, Step: 200, Loss: 0.4675059914588928\n",
      "Epoch: 114, Step: 400, Loss: 0.4544251561164856\n",
      "Epoch: 114, Step: 600, Loss: 0.6936167478561401\n",
      "Epoch: 115, Step: 0, Loss: 0.5466891527175903\n",
      "Epoch: 115, Step: 200, Loss: 0.4459732174873352\n",
      "Epoch: 115, Step: 400, Loss: 0.44392627477645874\n",
      "Epoch: 115, Step: 600, Loss: 0.6870867013931274\n",
      "Epoch: 116, Step: 0, Loss: 0.5959299802780151\n",
      "Epoch: 116, Step: 200, Loss: 0.4469839930534363\n",
      "Epoch: 116, Step: 400, Loss: 0.43936747312545776\n",
      "Epoch: 116, Step: 600, Loss: 0.6785456538200378\n",
      "Epoch: 117, Step: 0, Loss: 0.5796370506286621\n",
      "Epoch: 117, Step: 200, Loss: 0.4333476424217224\n",
      "Epoch: 117, Step: 400, Loss: 0.4199945032596588\n",
      "Epoch: 117, Step: 600, Loss: 0.6710163950920105\n",
      "Epoch: 118, Step: 0, Loss: 0.5649025440216064\n",
      "Epoch: 118, Step: 200, Loss: 0.44137173891067505\n",
      "Epoch: 118, Step: 400, Loss: 0.44284018874168396\n",
      "Epoch: 118, Step: 600, Loss: 0.6801427602767944\n",
      "Epoch: 119, Step: 0, Loss: 0.5516024827957153\n",
      "Epoch: 119, Step: 200, Loss: 0.42286768555641174\n",
      "Epoch: 119, Step: 400, Loss: 0.4060975909233093\n",
      "Epoch: 119, Step: 600, Loss: 0.6328401565551758\n",
      "Epoch: 120, Step: 0, Loss: 0.5091269016265869\n",
      "Epoch: 120, Step: 200, Loss: 0.4032653868198395\n",
      "Epoch: 120, Step: 400, Loss: 0.414663165807724\n",
      "Epoch: 120, Step: 600, Loss: 0.6379646062850952\n",
      "Epoch: 121, Step: 0, Loss: 0.5038497447967529\n",
      "Epoch: 121, Step: 200, Loss: 0.5032156705856323\n",
      "Epoch: 121, Step: 400, Loss: 0.433959424495697\n",
      "Epoch: 121, Step: 600, Loss: 0.644849419593811\n",
      "Epoch: 122, Step: 0, Loss: 0.48474645614624023\n",
      "Epoch: 122, Step: 200, Loss: 0.382722944021225\n",
      "Epoch: 122, Step: 400, Loss: 0.42887434363365173\n",
      "Epoch: 122, Step: 600, Loss: 0.6366005539894104\n",
      "Epoch: 123, Step: 0, Loss: 0.5377824306488037\n",
      "Epoch: 123, Step: 200, Loss: 0.3901214301586151\n",
      "Epoch: 123, Step: 400, Loss: 0.4079592227935791\n",
      "Epoch: 123, Step: 600, Loss: 0.6410304307937622\n",
      "Epoch: 124, Step: 0, Loss: 0.45751696825027466\n",
      "Epoch: 124, Step: 200, Loss: 0.4738709032535553\n",
      "Epoch: 124, Step: 400, Loss: 0.401677668094635\n",
      "Epoch: 124, Step: 600, Loss: 0.650673508644104\n",
      "Epoch: 125, Step: 0, Loss: 0.43759685754776\n",
      "Epoch: 125, Step: 200, Loss: 0.4245007634162903\n",
      "Epoch: 125, Step: 400, Loss: 0.41855350136756897\n",
      "Epoch: 125, Step: 600, Loss: 0.6397431492805481\n",
      "Epoch: 126, Step: 0, Loss: 0.478973925113678\n",
      "Epoch: 126, Step: 200, Loss: 0.39351770281791687\n",
      "Epoch: 126, Step: 400, Loss: 0.3841594457626343\n",
      "Epoch: 126, Step: 600, Loss: 0.62078857421875\n",
      "Epoch: 127, Step: 0, Loss: 0.5124757885932922\n",
      "Epoch: 127, Step: 200, Loss: 0.4641476571559906\n",
      "Epoch: 127, Step: 400, Loss: 0.5118380784988403\n",
      "Epoch: 127, Step: 600, Loss: 0.6146875023841858\n",
      "Epoch: 128, Step: 0, Loss: 0.44653525948524475\n",
      "Epoch: 128, Step: 200, Loss: 0.3579328656196594\n",
      "Epoch: 128, Step: 400, Loss: 0.41450661420822144\n",
      "Epoch: 128, Step: 600, Loss: 0.6146553754806519\n",
      "Epoch: 129, Step: 0, Loss: 0.4243009686470032\n",
      "Epoch: 129, Step: 200, Loss: 0.3393074870109558\n",
      "Epoch: 129, Step: 400, Loss: 0.3455761969089508\n",
      "Epoch: 129, Step: 600, Loss: 0.6279099583625793\n",
      "Epoch: 130, Step: 0, Loss: 0.45711055397987366\n",
      "Epoch: 130, Step: 200, Loss: 0.48688268661499023\n",
      "Epoch: 130, Step: 400, Loss: 0.38045352697372437\n",
      "Epoch: 130, Step: 600, Loss: 0.6434066295623779\n",
      "Epoch: 131, Step: 0, Loss: 0.45721012353897095\n",
      "Epoch: 131, Step: 200, Loss: 0.39982420206069946\n",
      "Epoch: 131, Step: 400, Loss: 0.40734902024269104\n",
      "Epoch: 131, Step: 600, Loss: 0.5933138132095337\n",
      "Epoch: 132, Step: 0, Loss: 0.43556898832321167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132, Step: 200, Loss: 0.3976813852787018\n",
      "Epoch: 132, Step: 400, Loss: 0.3904567062854767\n",
      "Epoch: 132, Step: 600, Loss: 0.6115921139717102\n",
      "Epoch: 133, Step: 0, Loss: 0.450636088848114\n",
      "Epoch: 133, Step: 200, Loss: 0.3586971163749695\n",
      "Epoch: 133, Step: 400, Loss: 0.2937397062778473\n",
      "Epoch: 133, Step: 600, Loss: 0.6369239091873169\n",
      "Epoch: 134, Step: 0, Loss: 0.40549635887145996\n",
      "Epoch: 134, Step: 200, Loss: 0.38578739762306213\n",
      "Epoch: 134, Step: 400, Loss: 0.34566059708595276\n",
      "Epoch: 134, Step: 600, Loss: 0.5239987969398499\n",
      "Epoch: 135, Step: 0, Loss: 0.39961519837379456\n",
      "Epoch: 135, Step: 200, Loss: 0.37337830662727356\n",
      "Epoch: 135, Step: 400, Loss: 0.4035714268684387\n",
      "Epoch: 135, Step: 600, Loss: 0.5170995593070984\n",
      "Epoch: 136, Step: 0, Loss: 0.3675796389579773\n",
      "Epoch: 136, Step: 200, Loss: 0.33262789249420166\n",
      "Epoch: 136, Step: 400, Loss: 0.3363152742385864\n",
      "Epoch: 136, Step: 600, Loss: 0.5332662463188171\n",
      "Epoch: 137, Step: 0, Loss: 0.4639468193054199\n",
      "Epoch: 137, Step: 200, Loss: 0.3382561504840851\n",
      "Epoch: 137, Step: 400, Loss: 0.3487515151500702\n",
      "Epoch: 137, Step: 600, Loss: 0.5482576489448547\n",
      "Epoch: 138, Step: 0, Loss: 0.4407210946083069\n",
      "Epoch: 138, Step: 200, Loss: 0.33451810479164124\n",
      "Epoch: 138, Step: 400, Loss: 0.46360835433006287\n",
      "Epoch: 138, Step: 600, Loss: 0.5246609449386597\n",
      "Epoch: 139, Step: 0, Loss: 0.3951089084148407\n"
     ]
    }
   ],
   "source": [
    "batch_size = 40\n",
    "model = RNNModel(100, 100, batch_size)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "criteria = nn.BCELoss()\n",
    "\n",
    "for e in range(200):\n",
    "    for i in range(800):\n",
    "        ids = total_list[i*batch_size:(i+1)*batch_size]\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for index in ids:\n",
    "            row = df.loc[df['Unnamed: 0'] == index]\n",
    "            label = int(float(row['ht']))\n",
    "            detail = clean_list_of_word(str(row['juicy_details']).split(' '), True)\n",
    "            x_batch.append(detail)\n",
    "            y_batch.append(label)\n",
    "        x_batch = get_batch_embedding(x_batch)\n",
    "        x = Variable(torch.from_numpy(x_batch).float())\n",
    "        y = Variable(torch.from_numpy(np.array(y_batch)).float())\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        hidden, c_t = model.init_hidden()\n",
    "        output = model(x, hidden, c_t)\n",
    "        loss = criteria(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 200 == 0:\n",
    "            print(\"Epoch: {}, Step: {}, Loss: {}\".format(e, i, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.6)",
   "language": "python",
   "name": "3point6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
